# -*- coding: utf-8 -*-
"""20Nov2024.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PzSQ7I2DiD7ZNOfL6hMrxycnZ3IZjwLn
"""

# Importing Libraries
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# Load the dataset
file_path = "HCAHPS_Hospital_2023_1.csv"
data_hc = pd.read_csv(file_path)

# Display the first few rows of the dataset
print("Dataset Preview:")
print(data_hc.head())

# Check dataset structure
print("\nDataset Information:")
print(data_hc.info())

# Display the columns before removal
print("Columns before removal:")
print(data_hc.columns)

# Remove the specified columns
columns_to_remove = [
    'Patient Survey Star Rating Footnote',
    'HCAHPS Answer Percent Footnote',
    'Number of Completed Surveys Footnote',
    'Survey Response Rate Percent Footnote'
]

# Dropping the columns
data_hc = data_hc.drop(columns=columns_to_remove)

# Display the columns after removal
print("\nColumns after removal:")
print(data_hc.columns)

# Check for missing values
print("\nMissing Values Count:")
print(data_hc.isnull().sum())

# Check dataset structure
print("\nDataset Information:")
print(data_hc.info())

# Check the column before conversion
print("Unique values in 'Patient Survey Star Rating' before conversion:")
print(data_hc['Patient Survey Star Rating'].unique())

print("\nUnique values in 'HCAHPS Answer Percent' before conversion:")
print(data_hc['HCAHPS Answer Percent'].unique())

print("\nUnique values in 'HCAHPS Linear Mean Value' before conversion:")
print(data_hc['HCAHPS Linear Mean Value'].unique())

print("\nUnique values in 'Number of Completed Surveys' before conversion:")
print(data_hc['Number of Completed Surveys'].unique())

print("\nUnique values in 'Survey Response Rate Percent' before conversion:")
print(data_hc['Survey Response Rate Percent'].unique())

# Convert to numeric, forcing non-numeric values to NaN
data_hc['Patient Survey Star Rating'] = pd.to_numeric(data_hc['Patient Survey Star Rating'], errors='coerce')
data_hc['HCAHPS Answer Percent'] = pd.to_numeric(data_hc['HCAHPS Answer Percent'], errors='coerce')
data_hc['HCAHPS Linear Mean Value'] = pd.to_numeric(data_hc['HCAHPS Linear Mean Value'], errors='coerce')
data_hc['Number of Completed Surveys'] = pd.to_numeric(data_hc['Number of Completed Surveys'], errors='coerce')
data_hc['Survey Response Rate Percent'] = pd.to_numeric(data_hc['Survey Response Rate Percent'], errors='coerce')

# Check the column after conversion
print("\nUnique values in 'Patient Survey Star Rating' after conversion:")
print(data_hc['Patient Survey Star Rating'].unique())

print("\nUnique values in 'HCAHPS Answer Percent' after conversion:")
print(data_hc['HCAHPS Answer Percent'].unique())

print("\nUnique values in 'HCAHPS Linear Mean Value' after conversion:")
print(data_hc['HCAHPS Linear Mean Value'].unique())

print("\nUnique values in 'Number of Completed Surveys' after conversion:")
print(data_hc['Number of Completed Surveys'].unique())

print("\nUnique values in 'Survey Response Rate Percent' after conversion:")
print(data_hc['Survey Response Rate Percent'].unique())

# Check for null values
print("\nCount of NaN values in 'Patient Survey Star Rating':")
print(data_hc['Patient Survey Star Rating'].isnull().sum())

print("\nCount of NaN values in 'HCAHPS Answer Percent':")
print(data_hc['HCAHPS Answer Percent'].isnull().sum())

print("\nCount of NaN values in 'HCAHPS Linear Mean Value':")
print(data_hc['HCAHPS Linear Mean Value'].isnull().sum())

print("\nCount of NaN values in 'Number of Completed Surveys':")
print(data_hc['Number of Completed Surveys'].isnull().sum())

print("\nCount of NaN values in 'Survey Response Rate Percent':")
print(data_hc['Survey Response Rate Percent'].isnull().sum())

# Summary statistics of numerical features
print("\nSummary Statistics:")
print(data_hc.describe())

# Categorical variables analysis
categorical_columns = data_hc.select_dtypes(include=['object']).columns
for col in categorical_columns:
    print(f"\nValue Counts for {col}:")
    print(data_hc[col].value_counts())

# Define the columns to exclude
exclude_columns = [
    "ZIP Code",
    "HCAHPS Answer Percent",
    "HCAHPS Linear Mean Value",
    "Number of Completed Surveys",
    "Survey Response Rate Percent"
]

# Select numerical columns and exclude the specified ones
numerical_columns = [
    col for col in data_hc.select_dtypes(include=['int64', 'float64']).columns
    if col not in exclude_columns
]

# Plot the distribution for numerical variables
for col in numerical_columns:
    plt.figure(figsize=(8, 4))
    sns.histplot(data_hc[col], kde=True, bins=30)
    plt.title(f"Distribution of {col}")
    plt.show()

# Define the columns to exclude
exclude_columns = [
    "ZIP Code",
    "HCAHPS Answer Percent",
    "HCAHPS Linear Mean Value",
    "Number of Completed Surveys",
    "Survey Response Rate Percent"
]

# Filter numerical_columns to exclude the specified columns
filtered_numerical_columns = [col for col in numerical_columns if col not in exclude_columns]

# Boxplots for numerical features to detect outliers
for col in filtered_numerical_columns:
    plt.figure(figsize=(8, 4))
    sns.boxplot(x=data_hc[col])
    plt.title(f"Boxplot of {col}")
    plt.show()

# Define the columns to exclude
exclude_columns = [
    "Facility Name",
    "Address",
    "City/Town",
    "State",
    "ZIP Code",
    "County/Parish",
    "ZIP Code",
    "HCAHPS Answer Percent",
    "Survey Response Rate Percent",
    "Start Date",
    "End Date"
]

# Select only numeric columns and exclude the specified ones
numeric_data = data_hc.select_dtypes(include=['int64', 'float64']).drop(columns=exclude_columns, errors='ignore')

# Check if there are numeric columns left after exclusion
if numeric_data.empty:
    print("No numeric columns available for correlation analysis.")
else:
    # Plot the heatmap for numeric columns
    plt.figure(figsize=(10, 6))
    sns.heatmap(numeric_data.corr(), annot=True, fmt=".2f", cmap="coolwarm")
    plt.title("Correlation Heatmap")
    plt.show()

# Define the columns to exclude
exclude_columns = [
    "Facility ID",
    "Address",
    "City/Town",
    "State",
    "County/Parish",
    "Telephone Number",
    "HCAHPS Measure ID",
    "Start Date",
    "End Date"
]

# Filter categorical columns to exclude the specified ones
filtered_categorical_columns = [col for col in categorical_columns if col not in exclude_columns]

# Bar plots for categorical variables
for col in filtered_categorical_columns:
    plt.figure(figsize=(10, 4))
    sns.countplot(data_hc[col], order=data_hc[col].value_counts().index, palette="viridis")
    plt.title(f"Count Plot of {col}")
    plt.xticks(rotation=45)
    plt.show()

# Define the columns to exclude
exclude_columns = [
    "Facility ID",
    "Address",
    "City/Town",
    "State",
    "ZIP Code",
    "County/Parish",
    "Telephone Number",
    "HCAHPS Measure ID",
    "HCAHPS Linear Mean Value",
    "Start Date",
    "End Date"
]

# Filter numerical columns to exclude the specified ones
numerical_columns = [
    col for col in data_hc.select_dtypes(include=['int64', 'float64']).columns
    if col not in exclude_columns
]

# Analyze relationships (bivariate analysis) for numerical columns
if len(numerical_columns) > 1:
    sns.pairplot(data_hc[numerical_columns], diag_kind="kde")
    plt.suptitle("Pair Plot of Numerical Variables", y=1.02)  # Adjust the title position
    plt.show()
else:
    print("Not enough numerical columns for bivariate analysis.")

# Example: Analyze how a numerical variable varies with a categorical variable
target_column = "Patient Survey Star Rating"  # Replace with a relevant numerical column
categorical_col = "Facility Name"  # Replace with a relevant categorical column

# Check if the target column and categorical column exist in the dataset
if target_column in numerical_columns and categorical_col in categorical_columns:
    # Filter the dataset to remove rows where the target numerical column has null values and values <= 0
    data_filtered = data_hc[(data_hc[target_column].notnull()) & (data_hc[target_column] > 0)]

    # Get the count of rows after filtering
    filtered_row_count = data_filtered.shape[0]
    print(f"Number of rows after filtering: {filtered_row_count}")

    # Check if there are any non-null, valid values left in the filtered dataset
    if filtered_row_count > 0:
        plt.figure(figsize=(12, 6))
        sns.boxplot(x=data_filtered[categorical_col], y=data_filtered[target_column], palette="Set2")
        plt.title(f"{target_column} vs {categorical_col}", fontsize=16)
        plt.xticks(rotation=45)
        plt.show()
    else:
        print(f"No valid values greater than 0 in '{target_column}'.")
else:
    print("No numeric or categorical columns available for analysis.")

# Group the data by 'Facility Name' and count the number of surveys (rows) for each facility
facility_survey_count = data_hc['Facility Name'].value_counts()

# Get the top 10 facilities with the highest survey count
top_10_facilities = facility_survey_count.head(10)

# Display the top 10 facilities
print("Top 10 Facilities with the Highest Survey Counts:")
print(top_10_facilities)

# Optionally, you can visualize this in a bar plot
plt.figure(figsize=(12, 6))
sns.barplot(x=top_10_facilities.index, y=top_10_facilities.values, palette="viridis")
plt.title("Top 10 Facilities with the Highest Survey Counts", fontsize=16)
plt.xticks(rotation=45)
plt.xlabel("Facility Name")
plt.ylabel("Survey Count")
plt.show()

# Group the data by 'Facility Name' and calculate the average survey rating for each facility
facility_avg_rating = data_hc.groupby('Facility Name')['Patient Survey Star Rating'].mean()

# Get the top 10 facilities with the highest average survey rating
top_10_facilities_rating = facility_avg_rating.sort_values(ascending=False).head(10)

# Display the top 10 facilities with the highest average ratings
print("Top 10 Facilities with the Highest Average Survey Ratings:")
print(top_10_facilities_rating)

# Optionally, you can visualize this in a bar plot
plt.figure(figsize=(12, 6))
sns.barplot(x=top_10_facilities_rating.index, y=top_10_facilities_rating.values, palette="viridis")
plt.title("Top 10 Facilities with the Highest Average Survey Ratings", fontsize=16)
plt.xticks(rotation=45)
plt.xlabel("Facility Name")
plt.ylabel("Average Survey Rating")
plt.show()

!pip install vaderSentiment

# Import required libraries
import pandas as pd
import re
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
from textblob import TextBlob
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
from nltk import download

# Download necessary NLTK resources
download('punkt')
download('stopwords')
download('wordnet')

# Download the 'punkt_tab' resource
download('punkt_tab')

# Initialize lemmatizer and VADER analyzer
lemmatizer = WordNetLemmatizer()
analyzer = SentimentIntensityAnalyzer()

# Function to clean and preprocess text
def clean_text(text):
    if not isinstance(text, str):
        text = str(text)

    # Step 1: Remove HTML tags and URLs
    text = re.sub(r'<.*?>', '', text)  # Remove HTML tags
    text = re.sub(r'http\S+|www\S+', '', text)  # Remove URLs

    # Step 2: Normalize text
    text = text.lower()  # Convert to lowercase
    text = re.sub(r'[^a-z\s]', '', text)  # Remove special characters and punctuation

    # Tokenize and remove stopwords
    tokens = word_tokenize(text)
    stop_words = set(stopwords.words('english'))
    tokens = [word for word in tokens if word not in stop_words]

    # Perform lemmatization
    tokens = [lemmatizer.lemmatize(word) for word in tokens]

    return ' '.join(tokens)

# Function to label sentiment using TextBlob
def label_sentiment_textblob(text):
    polarity = TextBlob(text).sentiment.polarity
    if polarity > 0:
        return 'positive'
    elif polarity == 0:
        return 'neutral'
    else:
        return 'negative'

# Function to label sentiment using VADER with adjustable threshold
def label_sentiment_vader_adjusted(text, neutral_threshold=0.1):
    sentiment_score = analyzer.polarity_scores(text)
    compound_score = sentiment_score['compound']
    if compound_score > neutral_threshold:
        return 'positive'
    elif compound_score < -neutral_threshold:
        return 'negative'
    else:
        return 'neutral'

# Function to refine sentiment based on rules
def refine_sentiment(row):
    text = row['Cleaned_Answer_Description']
    textblob_sentiment = row['TextBlob_Sentiment']
    vader_sentiment = row['VADER_Sentiment']

    # Override if specific terms are present
    if "never" in text:
        return 'negative'

    # Default to VADER if results mismatch
    if textblob_sentiment != vader_sentiment:
        return vader_sentiment
    return textblob_sentiment

# Preprocess the text
data_hc['Cleaned_Answer_Description'] = data_hc['HCAHPS Answer Description'].fillna("").apply(clean_text)

# Apply TextBlob sentiment labeling
data_hc['TextBlob_Sentiment'] = data_hc['Cleaned_Answer_Description'].apply(label_sentiment_textblob)

# Apply VADER sentiment labeling
data_hc['VADER_Sentiment'] = data_hc['Cleaned_Answer_Description'].apply(label_sentiment_vader_adjusted)

# Add polarity scores for analysis
data_hc['TextBlob_Polarity'] = data_hc['Cleaned_Answer_Description'].apply(lambda x: TextBlob(x).sentiment.polarity)
data_hc['VADER_Compound'] = data_hc['Cleaned_Answer_Description'].apply(lambda x: analyzer.polarity_scores(x)['compound'])

# Refine sentiment
data_hc['Final_Sentiment'] = data_hc.apply(refine_sentiment, axis=1)

# Save the final labeled dataset
data_hc.to_csv("sentiment_labeled_data.csv", index=False)

# Print mismatched sentiment examples
mismatched = data_hc[data_hc['TextBlob_Sentiment'] != data_hc['VADER_Sentiment']]
print("Mismatched Sentiments:")
print(mismatched[['Cleaned_Answer_Description', 'TextBlob_Sentiment', 'VADER_Sentiment']])

#Visualize the distribution of sentiments
#Identify common words using word clouds (WordCloud library)
!pip install wordcloud matplotlib seaborn

import pandas as pd
import matplotlib.pyplot as plt
from wordcloud import WordCloud
import seaborn as sns

# Plotting the sentiment distribution (VADER Sentiment)
plt.figure(figsize=(10, 6))
sns.countplot(x='VADER_Sentiment', data=data_hc, palette='Set2')
plt.title('Distribution of Sentiments (VADER)', fontsize=16)
plt.xlabel('Sentiment', fontsize=14)
plt.ylabel('Count', fontsize=14)
plt.show()

# Generate a Word Cloud for all cleaned text
all_text = ' '.join(data_hc['Cleaned_Answer_Description'])

# Create a word cloud for all text
wordcloud = WordCloud(width=800, height=400, background_color='white').generate(all_text)

# Display the word cloud
plt.figure(figsize=(10, 6))
plt.imshow(wordcloud, interpolation='bilinear')
plt.title('Word Cloud for All Text', fontsize=16)
plt.axis('off')
plt.show()

# Generate word clouds based on VADER sentiment labels
positive_text = ' '.join(data_hc[data_hc['VADER_Sentiment'] == 'positive']['Cleaned_Answer_Description'])
negative_text = ' '.join(data_hc[data_hc['VADER_Sentiment'] == 'negative']['Cleaned_Answer_Description'])
neutral_text = ' '.join(data_hc[data_hc['VADER_Sentiment'] == 'neutral']['Cleaned_Answer_Description'])

# Word cloud for positive sentiment
wordcloud_positive = WordCloud(width=800, height=400, background_color='white').generate(positive_text)
plt.figure(figsize=(10, 6))
plt.imshow(wordcloud_positive, interpolation='bilinear')
plt.title('Word Cloud for Positive Sentiment (VADER)', fontsize=16)
plt.axis('off')
plt.show()

# Word cloud for negative sentiment
wordcloud_negative = WordCloud(width=800, height=400, background_color='white').generate(negative_text)
plt.figure(figsize=(10, 6))
plt.imshow(wordcloud_negative, interpolation='bilinear')
plt.title('Word Cloud for Negative Sentiment (VADER)', fontsize=16)
plt.axis('off')
plt.show()

# Word cloud for neutral sentiment
wordcloud_neutral = WordCloud(width=800, height=400, background_color='white').generate(neutral_text)
plt.figure(figsize=(10, 6))
plt.imshow(wordcloud_neutral, interpolation='bilinear')
plt.title('Word Cloud for Neutral Sentiment (VADER)', fontsize=16)
plt.axis('off')
plt.show()

import pandas as pd
from sklearn.model_selection import train_test_split

# Prepare the features and labels
X = data_hc['Cleaned_Answer_Description']  # Features (cleaned text)
y = data_hc['VADER_Sentiment']  # Labels (VADER sentiments)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Display the shape of the training and testing sets
print("Training Data:")
print("X_train:", X_train.shape)
print("y_train:", y_train.shape)

print("\nTesting Data:")
print("X_test:", X_test.shape)
print("y_test:", y_test.shape)

#Convert Text to Numeric Representation
from sklearn.feature_extraction.text import CountVectorizer

# Sample DataFrame
import pandas as pd

# Initialize CountVectorizer
vectorizer = CountVectorizer()

# Fit and transform the 'Cleaned_Answer_Description' column to get the document-term matrix
X_bow = vectorizer.fit_transform(data_hc['Cleaned_Answer_Description'])

# Convert the result to a dense matrix and display it
X_bow_dense = X_bow.toarray()

# Show the feature names (words in the vocabulary)
print("Vocabulary:", vectorizer.get_feature_names_out())

# Show the document-term matrix
print("Document-Term Matrix (BoW):\n", X_bow_dense)

#Support Vector Machine (SVM)

from sklearn.svm import SVC
from sklearn.metrics import classification_report
from sklearn.feature_extraction.text import TfidfVectorizer # Import TfidfVectorizer

# Initialize the TF-IDF vectorizer
vectorizer = TfidfVectorizer()

# Fit the vectorizer to the training data and transform it
X_train_vec = vectorizer.fit_transform(X_train)

# Transform the test data using the fitted vectorizer
X_test_vec = vectorizer.transform(X_test)

# Initialize the SVM model
svm_model = SVC(kernel='linear')

# Train the model using the vectorized training data
svm_model.fit(X_train_vec, y_train)

# Make predictions using the vectorized test data
y_pred_svm = svm_model.predict(X_test_vec)

# Evaluate the model
print("SVM Classification Report:\n", classification_report(y_test, y_pred_svm))

#Naïve Bayes

from sklearn.naive_bayes import MultinomialNB
from sklearn.feature_extraction.text import TfidfVectorizer # Import for text vectorization

# Initialize the TF-IDF vectorizer
vectorizer = TfidfVectorizer()

# Fit the vectorizer to the training data and transform it
X_train_vec = vectorizer.fit_transform(X_train)

# Transform the test data using the fitted vectorizer
X_test_vec = vectorizer.transform(X_test)

# Initialize the Naïve Bayes model
nb_model = MultinomialNB()

# Train the model using the vectorized training data
nb_model.fit(X_train_vec, y_train)  # Use vectorized data

# Make predictions using the vectorized test data
y_pred_nb = nb_model.predict(X_test_vec)  # Use vectorized data

# Evaluate the model
print("Naïve Bayes Classification Report:\n", classification_report(y_test, y_pred_nb))

#Import necessary libraries
from sklearn.preprocessing import LabelEncoder
from sklearn.pipeline import Pipeline
from sklearn.neighbors import KNeighborsClassifier
from sklearn.compose import ColumnTransformer
from sklearn.metrics import classification_report
from sklearn.feature_extraction.text import TfidfVectorizer # Import for text vectorization

# Assuming your feature set X_train and X_test, and target variable y_train, y_test are already defined

# Create a LabelEncoder object
encoder = LabelEncoder()

# Encode the target variable (y_train and y_test)
y_train_encoded = encoder.fit_transform(y_train)
y_test_encoded = encoder.transform(y_test)


# Create a Pipeline with KNN classifier and TF-IDF vectorization
pipeline = Pipeline([
    ('tfidf', TfidfVectorizer()),  # Text vectorization using TF-IDF
    ('knn', KNeighborsClassifier())  # KNN model
])

# Fit the pipeline to the training data
#pipeline.fit(X_train['text_feature'], y_train_encoded) # Fit on the 'text_feature' column
pipeline.fit(X_train, y_train_encoded)

# Make predictions on the test data
#y_pred_knn = pipeline.predict(X_test['text_feature']) # Predict using 'text_feature' column
y_pred_knn = pipeline.predict(X_test)

# Get the original class labels (neutral, positive, negative)
target_names = encoder.classes_

# Evaluate the model and display the report with original labels
print("KNN Classification Report:\n", classification_report(y_test_encoded, y_pred_knn, target_names=target_names))

#Train Deep Learning Models - LSTM

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Embedding, Dropout
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.preprocessing.text import Tokenizer # Import Tokenizer
from sklearn.preprocessing import LabelEncoder # Import LabelEncoder
from sklearn.metrics import classification_report # Import for classification report


# 1. Tokenize the text data
tokenizer = Tokenizer(num_words=5000)  # Limit vocabulary size to 5000
#tokenizer.fit_on_texts(X_train['text_feature']) # Fit on the 'text_feature' column
tokenizer.fit_on_texts(X_train)

# 2. Convert text to sequences
#X_train_sequences = tokenizer.texts_to_sequences(X_train['text_feature'])
#X_test_sequences = tokenizer.texts_to_sequences(X_test['text_feature'])
X_train_sequences = tokenizer.texts_to_sequences(X_train)
X_test_sequences = tokenizer.texts_to_sequences(X_test)

# Pad the sequences
X_train_pad = pad_sequences(X_train_sequences, maxlen=100)
X_test_pad = pad_sequences(X_test_sequences, maxlen=100)

# ----> Encode the target variable <----
# Create a LabelEncoder object
encoder = LabelEncoder()

# Encode the target variable (y_train and y_test)
y_train_encoded = encoder.fit_transform(y_train)
y_test_encoded = encoder.transform(y_test)

# LSTM Model
model_lstm = Sequential()
model_lstm.add(Embedding(input_dim=5000, output_dim=128, input_length=100))
model_lstm.add(LSTM(128, return_sequences=True))
model_lstm.add(Dropout(0.2))
model_lstm.add(LSTM(64))
model_lstm.add(Dense(1, activation='sigmoid'))  # For binary classification

model_lstm.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train the model
model_lstm.fit(X_train_pad, y_train_encoded, epochs=5, batch_size=64, validation_data=(X_test_pad, y_test_encoded))


# Evaluate the model
loss, accuracy = model_lstm.evaluate(X_test_pad, y_test_encoded)
print(f'LSTM Model Accuracy: {accuracy}')

# Make predictions on the test data
y_pred_lstm = model_lstm.predict(X_test_pad)
y_pred_lstm_classes = (y_pred_lstm > 0.5).astype(int) # Convert probabilities to class labels (0 or 1)

# Get the original class labels (neutral, positive, negative)
target_names = encoder.classes_

# Evaluate the model and display the report with original labels
report = classification_report(y_test_encoded, y_pred_lstm_classes, target_names=target_names, digits=2, output_dict=True) # Get report as a dictionary

# Print the report in the desired format
print("LSTM Classification Report:")
print("{:15s}{:10s}{:10s}{:10s}{:10s}".format("", "precision", "recall", "f1-score", "support"))
for label in target_names:
    print("{:15s}{:10.2f}{:10.2f}{:10.2f}{:10d}".format(
        label,
        report[label]['precision'],
        report[label]['recall'],
        report[label]['f1-score'],
        report[label]['support']
    ))
print()
print("{:15s}{:10.2f}{:10.2f}{:10.2f}{:10.0f}".format(
    "accuracy",
    report['accuracy'],
    "",
    "",
    report['macro avg']['support']
))
print("{:15s}{:10.2f}{:10.2f}{:10.2f}{:10.0f}".format(
    "macro avg",
    report['macro avg']['precision'],
    report['macro avg']['recall'],
    report['macro avg']['f1-score'],
    report['macro avg']['support']
))
print("{:15s}{:10.2f}{:10.2f}{:10.2f}{:10.0f}".format(
    "weighted avg",
    report['weighted avg']['precision'],
    report['weighted avg']['recall'],
    report['weighted avg']['f1-score'],
    report['weighted avg']['support']
))

#Train Deep Learning Models - Tensor Flow

#Import necessary libraries
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Embedding, Dropout
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.preprocessing.text import Tokenizer # Import Tokenizer

# 1. Tokenize the text data
tokenizer = Tokenizer(num_words=5000)  # Limit vocabulary size to 5000
tokenizer.fit_on_texts(X_train) # Fit tokenizer on training data to create vocabulary

# 2. Convert text to sequences
X_train_sequences = tokenizer.texts_to_sequences(X_train)
X_test_sequences = tokenizer.texts_to_sequences(X_test)

# Pad the sequences
X_train_pad = pad_sequences(X_train_sequences, maxlen=100) # Now using sequences of integers
X_test_pad = pad_sequences(X_test_sequences, maxlen=100) # Now using sequences of integers

# ----> Encode the target variable <----
# Create a LabelEncoder object
encoder = LabelEncoder()

# Fit the encoder on all unique labels to ensure consistent encoding
all_labels = y_train.unique().tolist() + y_test.unique().tolist()
encoder.fit(all_labels)

# Encode the target variable (y_train and y_test)
y_train_encoded = encoder.transform(y_train)
y_test_encoded = encoder.transform(y_test)


# LSTM Model
model_lstm = Sequential()
model_lstm.add(Embedding(input_dim=5000, output_dim=128, input_length=100))
model_lstm.add(LSTM(128, return_sequences=True))
model_lstm.add(Dropout(0.2))
model_lstm.add(LSTM(64))
model_lstm.add(Dense(1, activation='sigmoid'))  # For binary classification

model_lstm.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train the model
model_lstm.fit(X_train_pad, y_train_encoded, epochs=5, batch_size=64, validation_data=(X_test_pad, y_test_encoded))

# Evaluate the model
loss, accuracy = model_lstm.evaluate(X_test_pad, y_test)
print(f'LSTM Model Accuracy: {accuracy}')

#Train Deep Learning Models - CNN

from tensorflow.keras.layers import Conv1D, MaxPooling1D

# CNN Model
model_cnn = Sequential()
model_cnn.add(Embedding(input_dim=5000, output_dim=128, input_length=100))
model_cnn.add(Conv1D(128, 5, activation='relu'))
model_cnn.add(MaxPooling1D(pool_size=2))
model_cnn.add(LSTM(64))
model_cnn.add(Dense(1, activation='sigmoid'))

model_cnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train the model
model_cnn.fit(X_train_pad, y_train, epochs=5, batch_size=64, validation_data=(X_test_pad, y_test))

# Evaluate the model
loss, accuracy = model_cnn.evaluate(X_test_pad, y_test)
print(f'CNN Model Accuracy: {accuracy}')

#Train Deep Learning Models - RNN

from tensorflow.keras.layers import SimpleRNN

# RNN Model
model_rnn = Sequential()
model_rnn.add(Embedding(input_dim=5000, output_dim=128, input_length=100))
model_rnn.add(SimpleRNN(128, return_sequences=True))
model_rnn.add(Dropout(0.2))
model_rnn.add(SimpleRNN(64))
model_rnn.add(Dense(1, activation='sigmoid'))

model_rnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train the model
model_rnn.fit(X_train_pad, y_train, epochs=5, batch_size=64, validation_data=(X_test_pad, y_test))

# Evaluate the model
loss, accuracy = model_rnn.evaluate(X_test_pad, y_test)
print(f'RNN Model Accuracy: {accuracy}')

#Train Deep Learning Models - DNN

# Import necessary libraries
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split

# Assuming you have your feature set (X) and target variable (y) already loaded
# If not, load them here or adjust accordingly.

# Example data: Replace this with your actual dataset
# X, y = your_data_loading_function()

# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Label encoding the target variable (if it's categorical)
encoder = LabelEncoder()
y_train_encoded = encoder.fit_transform(y_train)
y_test_encoded = encoder.transform(y_test)

# Define the model
model = Sequential()

# Add input layer and first hidden layer
model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))

# Optionally, add a Dropout layer to prevent overfitting
model.add(Dropout(0.2))

# Add second hidden layer
model.add(Dense(64, activation='relu'))

# Add output layer (use 'softmax' for multi-class classification)
model.add(Dense(len(encoder.classes_), activation='softmax'))

# Compile the model
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# Train the model
history = model.fit(X_train, y_train_encoded, epochs=20, batch_size=32, validation_split=0.2)

# Make predictions on the test data
y_pred_dnn = model.predict(X_test)
y_pred_dnn_classes = encoder.inverse_transform(y_pred_dnn.argmax(axis=1))

# Evaluate the model
print("DNN Classification Report:\n", classification_report(y_test, y_pred_dnn_classes))

# Optionally, plot the loss and accuracy curves
import matplotlib.pyplot as plt

plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label='val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0, 1])
plt.legend(loc='lower right')
plt.show()

!pip install streamlit

!pip install pyngrok

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# 
# # Streamlit app example
# st.title("Hello from Streamlit in Colab!")
# st.write("This app runs directly from Google Colab.")
#

from pyngrok import ngrok

# Run Streamlit app
!streamlit run app.py &

# Create a public URL
url = ngrok.connect(port='8501')
print(f"Access the Streamlit app here: {url}")

from pyngrok import ngrok

# Connect to Streamlit's default port 8501
public_url = ngrok.connect(port='8501')
print(f"Public URL: {public_url}")